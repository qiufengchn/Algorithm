{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 输入模块\n",
    "\n",
    "首先，单个或批量文本/提示被输入模型。例如：图中的\"Hello World\"。输入模型的必须是数字格式，因为模型无法直接处理文本。分词器将这些文本/提示转换为标记ID（词汇表中标记的索引号表示）。\n",
    "\n",
    "我们将使用Tiny Shakespeare数据集构建词汇表并训练模型。Llama 3模型使用TikToken作为分词器，这是一种子词分词器。但是我们这个实现将使用字符级分词器。这样做的主要原因是让我们能够自行构建词汇表和分词器，包括编码和解码函数，这样可以深入理解底层工作原理并完全掌控代码。每个标记ID将被转换为128维的嵌入向量（原始Llama 3 8B中为4096维）。\n",
    "\n",
    "然后这些嵌入将被传递到下一个解码器模块。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必要的库 \n",
    "import torch \n",
    "from torch import nn \n",
    "from torch.nn import functional as F \n",
    "import math \n",
    "import numpy as np \n",
    "import time \n",
    "from dataclasses import dataclass \n",
    "from typing import Optional, Tuple, List \n",
    "import pandas as pd \n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 步骤1: 输入模块 ###  \n",
    "# 使用Tiny Shakespeare数据集实现字符级分词器。部分字符级分词器代码参考自Andrej Karpathy的GitHub仓库\n",
    "# (https://github.com/karpathy/nanoGPT/blob/master/data/shakespeare_char/prepare.py)\n",
    "# 加载tiny_shakespeare数据文件 (https://github.com/tamangmilan/llama3/blob/main/tiny_shakespeare.txt)  \n",
    "device: str = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# 根据可用性分配设备为cuda或cpu  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载tiny_shakespeare.txt数据文件\n",
    "with open('tiny_shakespeare.txt', 'r') as f: \n",
    "    data = f.read() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通过提取tiny_shakespeare数据中的所有唯一字符准备词汇表 \n",
    "vocab = sorted(list(set(data))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练Llama 3模型需要额外的标记，如<|begin_of_text|>、<|end_of_text|>和<|pad_id|>，将它们添加到词汇表中 \n",
    "vocab.extend(['<|begin_of_text|>','<|end_of_text|>','<|pad_id|>']) \n",
    "vocab_size = len(vocab) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
