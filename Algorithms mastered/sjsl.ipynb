{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 引入必要的库\n",
    "导入必要的Python库，例如NumPy和Pandas。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 引入必要的库\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 随机森林的基本概念\n",
    "介绍随机森林的基本概念，包括集成学习和弱学习器的定义。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\hat{f}(x) = \\frac{1}{M} \\sum_{m=1}^{M} f_m(x)\n",
    "$$\n",
    "\n",
    "其中，$\\hat{f}(x)$ 是集成模型的预测结果，$M$ 是弱学习器的数量，$f_m(x)$ 是第 $m$ 个弱学习器的预测结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 随机森林的基本概念\n",
    "\n",
    "随机森林（Random Forest）是一种集成学习方法，其核心思想是通过组合多棵决策树（弱学习器），利用“Bagging + 特征随机化”来提升模型的泛化能力和鲁棒性。\n",
    "\n",
    "## 集成学习\n",
    "\n",
    "集成学习（Ensemble Learning）是一种通过构建并结合多个学习器来完成学习任务的方法。其目标是通过集成多个弱学习器来构建一个强学习器，从而提高模型的预测性能。\n",
    "\n",
    "## 弱学习器\n",
    "\n",
    "弱学习器（Weak Learner）是指性能稍微优于随机猜测的学习器。在随机森林中，决策树通常作为弱学习器。决策树通过递归地将数据集划分为更小的子集来进行预测。\n",
    "\n",
    "# ## 随机森林的构建\n",
    "\n",
    "随机森林通过以下步骤构建：\n",
    "\n",
    "1. 从训练集中有放回地随机抽取多个样本，构建多个训练子集。\n",
    "2. 对于每个训练子集，构建一棵决策树。在构建过程中，每次划分节点时随机选择部分特征进行选择。\n",
    "3. 将所有决策树的预测结果进行平均（回归问题）或投票（分类问题），得到最终的预测结果。\n",
    "\n",
    "随机森林的优点包括：\n",
    "\n",
    "- 能够处理高维数据且不易过拟合。\n",
    "- 能够评估特征的重要性。\n",
    "- 对于缺失数据具有鲁棒性。\n",
    "\n",
    "通过以上步骤，随机森林能够有效地提高模型的泛化能力和鲁棒性。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging 方法\n",
    "解释Bagging方法及其在随机森林中的应用。公式：$$\\hat{f}(x) = \\frac{1}{B} \\sum_{b=1}^{B} f_b(x)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging 方法\n",
    "\n",
    "Bagging（Bootstrap Aggregating）是一种通过多次有放回地从原始数据集中抽取子样本来训练多个模型的方法。每个模型的预测结果通过平均（回归问题）或投票（分类问题）来得到最终的预测结果。\n",
    "\n",
    "在随机森林中，Bagging 方法用于构建多个决策树，每棵树都在不同的子样本上进行训练。\n",
    "\n",
    "公式如下：\n",
    "\n",
    "$$\n",
    "\\hat{f}(x) = \\frac{1}{B} \\sum_{b=1}^{B} f_b(x)\n",
    "$$\n",
    "\n",
    "其中，$\\hat{f}(x)$ 是最终的预测结果，$B$ 是决策树的数量，$f_b(x)$ 是第 $b$ 棵决策树的预测结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征随机化\n",
    "描述特征随机化的过程及其对模型性能的影响。公式：$$\\text{Random feature subset} = \\{X_{i1}, X_{i2}, ..., X_{im}\\}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型准确率: 0.37\n"
     ]
    }
   ],
   "source": [
    "# 示例代码：特征随机化的实现\n",
    "\n",
    "# 生成一个随机数据集\n",
    "np.random.seed(42)\n",
    "X = np.random.rand(100, 10)  # 100个样本，10个特征\n",
    "y = np.random.randint(0, 2, 100)  # 二分类标签\n",
    "\n",
    "# 划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 构建随机森林分类器\n",
    "rf = RandomForestClassifier(n_estimators=100, max_features='sqrt', random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# 预测并计算准确率\n",
    "y_pred = rf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'模型准确率: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 随机森林的优缺点\n",
    "总结随机森林的主要优点和缺点。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 随机森林的优缺点\n",
    "\n",
    "## 优点\n",
    "\n",
    "1. **高准确率**：随机森林通常具有较高的准确率，尤其在分类问题上表现优异。\n",
    "2. **抗过拟合**：由于随机森林通过集成多棵决策树进行预测，能够有效地减少过拟合现象。\n",
    "3. **处理高维数据**：随机森林能够处理高维数据集，并且在特征选择上具有一定的鲁棒性。\n",
    "4. **特征重要性评估**：随机森林可以评估每个特征的重要性，帮助我们理解数据的结构。\n",
    "5. **鲁棒性强**：对于缺失数据和噪声数据具有较强的鲁棒性。\n",
    "\n",
    "## 缺点\n",
    "\n",
    "1. **计算开销大**：由于需要训练大量的决策树，随机森林的训练过程可能会比较耗时。\n",
    "2. **模型复杂性高**：随机森林模型包含大量的决策树，模型的复杂性较高，不易解释。\n",
    "3. **内存消耗大**：随机森林需要存储大量的决策树，可能会占用较多的内存资源。\n",
    "\n",
    "公式如下：\n",
    "\n",
    "$$\n",
    "\\text{Gini impurity} = 1 - \\sum_{i=1}^{n} p_i^2\n",
    "$$\n",
    "\n",
    "其中，$p_i$ 是第 $i$ 类的概率，$n$ 是类别的数量。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
